import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from pandas import DataFrame

pd.options.display.width = None
pd.options.display.max_columns = None
pd.set_option('display.max_rows', 3000)
pd.set_option('display.max_columns', 3000)

# Настройки визуализации
sns.set(style="whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

# Загрузка данных
print("\nЗагрузка данных")
df: DataFrame = pd.read_csv("../data/kursovik_data.csv")

# Переименуем некоторые колонки
print('\nПереименуем некоторые колонки')
df = df.rename(columns={
    "IC50, mM": "IC50",
    "CC50, mM": "CC50"
})

### ОБЩАЯ ИНФОРМАЦИЯ О ДАННЫХ
print("\nОбщая структура данных:")
print(df.info())
print(f'\nФорма датасета: {df.shape}')

print("\nОписательная статистика (основные показатели):")
print(df.describe().T)

print("\nСписок колонок:", df.columns.tolist())

# Анализ пропусков.
print("\nАнализ пропусков.")
missing = df.isnull().sum()
missing = missing[missing > 0].sort_values(ascending=False)
print("\nПризнаки с пропущенными значениями:")
print(missing)

# Визуализация пропусков
print("\nВизуализация пропусков")
plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap="viridis")
plt.title("Матрица пропусков")
plt.show()

# Проведём предобработку данных
print("\nПроведём предобработку данных")

# Удалим явно ненужную колонку
print("\nУдалим явно ненужную колонку")
if "Unnamed: 0" in df.columns:
    df.drop(columns=["Unnamed: 0"], inplace=True)

# Есть пропуски, но их очень мало, просто удалим их.
print("\nЕсть пропуски, но их очень мало, просто удалим их.")
target_cols = ['IC50', 'CC50', 'SI']
df = df.dropna()

# Проведём анализ распределения целевых признаков. Визуализируем распределения с помощью гистограмм.
print("\nПроведём анализ распределения целевых признаков. Визуализируем распределения с помощью гистограмм.")

for col in target_cols:
    plt.figure()
    sns.histplot(df[col], bins=30, kde=True)
    plt.title(f"Распределение {col}")
    plt.xlabel(col)
    plt.ylabel("Количество")
    plt.show()

# Так как распределения целевых признаков сильно скошены, а это ухудшит обучение моделей, они требуют логарифмирования для приведения к виду более похожему на нормальное распределение.
print("\nТак как распределения целевых признаков сильно скошены, а это ухудшит обучение моделей, они требуют логарифмирования для приведения к виду более похожему на нормальное распределение.")
# Проведём логарифмирование логарифмирование, добавим новые признаки на основе целевых.
print("\nПроведём логарифмирование логарифмирование, добавим новые признаки на основе целевых.")
for col in target_cols:
    log_col = f"log_{col.split(',')[0]}"
    df[log_col] = np.log1p(df[col])

# Расширим перечень целевых признаков добавив логарифмированные.
print("\nРасширим перечень целевых признаков добавив логарифмированные.")
target_cols = ['IC50', 'CC50', 'SI', 'log_IC50', 'log_CC50', 'log_SI']
log_cols = ['log_IC50', 'log_CC50', 'log_SI']

# Визуализируем распределения логарифмированных признаков с помощью гистограмм.
print("\nВизуализируем распределения логарифмированных признаков с помощью гистограмм.")

for col in log_cols:
    plt.figure()
    sns.histplot(df[col], bins=30, kde=True)
    plt.title(f"Распределение {col}")
    plt.xlabel(col)
    plt.ylabel("Количество")
    plt.show()


# Проведём анализ выбросов. Визуализируем с помощью ящиков с усами.
print("\nПроведём анализ выбросов. Визуализируем с помощью ящиков с усами.")

for col in target_cols:
    plt.figure()
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot для {col}")
    plt.show()


# Присутствуют выбросы. Так как из теоретической справки нам известно, что IC50 более 1000 это почти всегда выброс и очень токсично.
# CC50 может быть каким угодно, чем больше тем менее токсично. SI лучше пересчитать, потому как оно вычисляется как CC50 / IC50, и обычно не бывают выше 1000.
# Следовательно, есть выбросы и их нужно убрать. Для начала обрежем по верхнему перцентилю (например, 99-й).
print('''\nПрисутствуют выбросы. Так как из теоретической справки нам известно, что IC50 более 1000 это почти всегда выброс и очень токсично. 
CC50 может быть каким угодно, чем больше тем менее токсично. 
SI лучше пересчитать, потому как оно вычисляется как CC50 / IC50, и обычно не бывают выше 1000. 
Следовательно, есть выбросы и их нужно убрать. Для начала обрежем по верхнему перцентилю (например, 99-й).''')

for col in target_cols:
    upper = df[col].quantile(0.99)
    df = df[df[col] <= upper]


# Краткий итог
print("\nКраткий итог")
print(f"Размер после очистки: {df.shape}")
print("Добавленные признаки:", target_cols)


### Визуализируем корреляцию между целевыми признаками, в том числе созданными на их основе.
print("\nВизуализируем корреляцию между целевыми признаками, в том числе созданными на их основе.")
plt.figure()
sns.heatmap(df[target_cols].corr(), annot=True, cmap='coolwarm')
plt.title("Корреляции между IC50, CC50 и SI  и логарифмированными версиями")
plt.show()

# Корреляция между логарифмированными признаками выше чем между оригинальными. Далее для обучения моделей следует использовать логарифмированные признаки.
print('''\nКорреляция между логарифмированными признаками выше чем между оригинальными. 
Далее для обучения моделей следует использовать логарифмированные признаки. 
А само наличие высокой корреляции позитивно скажется на качестве построенных моделей.''')



# Построим корреляционную матрицу всех признаков.
print("\nПостроим корреляционную матрицу всех признаков.")
corr_matrix = df.corr(numeric_only=True)
high_corr = corr_matrix[target_cols].drop(index=target_cols)

# Есть признаки высоко скоррелированные между собой, то-есть мультиколлинеарность и признаки мало коррелированные с таргетами. Решать эту проблему будем используя PCA.
print('\nЕсть признаки высоко скоррелированные между собой, то-есть мультиколлинеарность и признаки мало коррелированные с таргетами. Решать эту проблему будем используя PCA.')

# "Покажем наиболее коррелирующие с SI признаки."
# print("\nВизуализируем наиболее коррелирующие с SI признаки.")
# top_corr = high_corr.abs().sort_values(by='SI', ascending=False).head(10)
# print(top_corr)

# Покажем наиболее коррелирующие с таргетами признаки. Эти признаки имеют наибольшую линейную связь с таргетом. Они приоритетны для моделей.
print("\nПокажем наиболее коррелирующие с таргетами признаки. Эти признаки имеют наибольшую линейную связь с таргетом. Они приоритетны для моделей.")
for target in target_cols:
    # to_drop = [target, target.split('log_', 1) if 'log' in target else f'log_{target}']
    top_feats = corr_matrix[target].drop(target_cols).abs().sort_values(ascending=False).head(10)
    plt.figure(figsize=(10, 6))
    sns.barplot(x=top_feats.values, y=top_feats.index)
    plt.title(f"Топ 10 признаков по корреляции с {target}")
    plt.xlabel("Абсолютная корреляция")
    plt.ylabel("Признак")
    plt.show()


# Проверка на дисбаланс классов для задач классификации, важно для выбора метрик (AUC, F1 и пр.)
print("Проверка на дисбаланс классов для задач классификации, важно для выбора метрик (AUC, F1 и пр.)")
df["IC50>median"] = (df["IC50"] > df["IC50"].median()).astype(int)
df["CC50>median"] = (df["CC50"] > df["CC50"].median()).astype(int)
df["SI>median"] = (df["SI"] > df["SI"].median()).astype(int)
df["SI>8"] = (df["SI"] > 8).astype(int)

class_targets = ["IC50>median", "CC50>median", "SI>median", "SI>8"]

for col in class_targets:
    sns.countplot(x=df[col])
    plt.title(f"Распределение классов для {col}")
    plt.xlabel("Класс")
    plt.ylabel("Количество")
    plt.show()

print('\nКлассы достаточно сбалансированы для построения классификации.')


print('''\nВыводы:
1. Есть ненужный признак который можно удалить
2. Распределения целевых переменных сильно скошены и содержат выбросы, поэтому мы их логарифмировали и очистили.
3. Отобрали списки наиболее полезных признаков для построения моделей, хотя в дальнейшем будем это делать с помощью PCA.
4. Классы достаточно сбалансированы для построения классификации.
5. Изучая теорию пришли к выводу что можно провести фича инжениринг: 
- Логарифмирование сильно скошенных целевых переменных
- Создание бинарных меток для задач классификации
- Взаимодействия признаков (например, SI = CC50 / IC50 возможно переопределить)
- Статистические производные признаки — например, среднее/сумма/разность между группами дескрипторов
- Группировка похожих дескрипторов — по типу (например, все fr_ или VSA_, и брать суммы или PCA)''')

print("\nEDA завершён. Можно переходить к построению моделей.")
