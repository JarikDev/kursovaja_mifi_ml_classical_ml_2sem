import math

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from pandas import DataFrame
from tabulate import tabulate

# Настройки визуализации
sns.set(style="whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)
pd.options.display.width = None
pd.options.display.max_columns = None
pd.set_option('display.max_rows', 3000)
pd.set_option('display.max_columns', 3000)


def visualise_distribution(df, column):
    plt.figure()
    sns.histplot(df[column], bins=30, kde=True)
    plt.title(f"Распределение {column}")
    plt.xlabel(column)
    plt.ylabel("Количество")
    plt.show()


def visualise_distributions(df, columns):
    ncols = int(abs(math.sqrt(len(columns))))
    n = len(columns)
    nrows = (n + ncols - 1) // ncols

    fig, axes = plt.subplots(
        nrows=nrows,
        ncols=ncols,
        figsize=(5 * ncols, 4 * nrows)
    )

    # Строим графики и скрываем пустые области
    for idx, ax in enumerate(axes.flat):
        if idx < n:
            column = columns[idx]
            sns.histplot(df[column], ax=ax, bins=30, kde=True)
            ax.set_title(column)
        else:
            ax.set_visible(False)

    plt.tight_layout()


def visualise_box_plot(df, column):
    plt.figure()
    sns.boxplot(x=df[column])
    plt.title(f"Boxplot для {column}")
    plt.show()


def visualise_box_plots(df, columns):
    figsize_base = 5
    orientation = 'h'

    if not columns:
        print("Нет колонок для отображения!")
        return

    n = len(columns)
    ncols = 1
    if n > 3:
        ncols = min(math.ceil(math.sqrt(n)), 4)  # Ограничиваем максимум 4 колонки в строке
    nrows = math.ceil(n / ncols)

    fig, axes = plt.subplots(
        nrows=nrows,
        ncols=ncols,
        figsize=(figsize_base * ncols, figsize_base * nrows * 0.8)
    )

    # Настройки стиля для boxplot
    boxprops = dict(facecolor='#1f77b4', linewidth=1.5)  # Цветовая схема matplotlib
    flierprops = dict(marker='o', markersize=3, markerfacecolor='red')

    for idx, ax in enumerate(axes.flat):
        if idx < n:
            column = columns[idx]

            # Строим boxplot с учетом ориентации
            if orientation == 'v':
                sns.boxplot(y=df[column], ax=ax, width=0.6, boxprops=boxprops, flierprops=flierprops)
                ax.set_ylabel("Значения", fontsize=9)
            else:
                sns.boxplot(x=df[column], ax=ax, width=0.6, boxprops=boxprops, flierprops=flierprops)
                ax.set_xlabel("Значения", fontsize=9)

            # Настройка оформления
            ax.set_title(f"{column}\n", fontsize=10)
            ax.grid(True, axis='y' if orientation == 'v' else 'x', alpha=0.3)
            ax.tick_params(labelsize=8)

            # Убираем лишние оси
            if orientation == 'v':
                ax.set_xlabel('')
                ax.set_xticks([])
            else:
                ax.set_ylabel('')
                ax.set_yticks([])
        else:
            ax.set_visible(False)

    plt.tight_layout(pad=2.0)
    plt.show()


def visualise_top_correlated_features(corr_matrix, target, target_cols, n):
    top_feats = corr_matrix[target].drop(target_cols).abs().sort_values(ascending=False).head(n)
    plt.figure(figsize=(10, 6))
    sns.barplot(x=top_feats.values, y=top_feats.index)
    plt.title(f"Топ 10 признаков по корреляции с {target}")
    plt.xlabel("Абсолютная корреляция")
    plt.ylabel("Признак")
    plt.show()


def visualise_class_balance(df, column):
    sns.countplot(x=df[column])
    plt.title(f"Распределение классов для {column}")
    plt.xlabel("Класс")
    plt.ylabel("Количество")
    plt.show()


def visualise_class_balances(df, columns):
    """
    Визуализирует распределение классов для массива колонок на квадратной сетке.

    Аргументы:
        df (pd.DataFrame): датафрейм с данными.
        columns (list): список названий колонок.
    """
    n = len(columns)
    n_cols = math.ceil(math.sqrt(n))
    n_rows = math.ceil(n / n_cols)

    width_per_plot = 4
    height_per_plot = 3
    figsize = (n_cols * width_per_plot, n_rows * height_per_plot)

    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)
    axes = axes.flatten()

    for i, col in enumerate(columns):
        sns.countplot(x=df[col], ax=axes[i])
        axes[i].set_title(f"Распределение классов для {col}")
        axes[i].set_xlabel("Класс")
        axes[i].set_ylabel("Количество")

    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()


def visualise_corr_mx(df, columns=None):
    plt.figure()
    if columns is None or len(columns) == 0:
        sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
    else:
        sns.heatmap(df[target_cols].corr(), annot=True, cmap='coolwarm')
    plt.title("Матрица корреляций")
    plt.show()


# Загрузка данных
print("\nЗагрузка данных")
df: DataFrame = pd.read_csv("../data/kursovik_data.csv")

# Переименуем некоторые колонки
print('\nПереименуем некоторые колонки')
df = df.rename(columns={
    "IC50, mM": "IC50",
    "CC50, mM": "CC50"
})

### Общая информация о данных
print("\nОбщая информация о данных:")
print(df.info())
print(f'\nФорма датасета: {df.shape}')

print('''\nДля эффективного построения моделей машинного обучения нужно понимать какие данные к нам попали. 
Каким законам и закономерностям подвержены. 
Какие признаки можно добавить, доработать, переформатировать или выкинуть. 
Для решения этой задачи проанализируем признаки (колонки) в датасете.''')
print("\nСписок признаков:", df.columns.tolist())
print('''\nЭтот набор колонок представляет собой богатое множество химических дескрипторов, 
позволяющих анализировать физико-химические, топологические, электронные и структурные свойства молекул.

Описание всех колонок:
Unnamed: 0 — индекс строки из исходного файла, не несёт химической информации.
IC50 — концентрация вещества, вызывающая 50% ингибирование активности (показатель эффективности).
CC50 — концентрация, при которой наблюдается 50% цитотоксичности (показатель токсичности).
SI — селективный индекс, отношение CC50 к IC50, характеризует терапевтический потенциал.

MaxAbsEStateIndex, MaxEStateIndex, MinAbsEStateIndex, MinEStateIndex — максимальные и минимальные значения (по модулю и без) электронного состояния атомов (EState), отражающие электронное окружение.
qed — показатель "drug-likeness" (quantitative estimate of drug-likeness), оценивает пригодность молекулы как лекарства.
SPS — сумма квадратов частичных зарядов, отражает распределение заряда по молекуле.
MolWt — молекулярная масса.
HeavyAtomMolWt — молекулярная масса без учёта водорода.
ExactMolWt — точная молекулярная масса на основе атомных масс из таблицы Менделеева.
NumValenceElectrons — число валентных электронов.
NumRadicalElectrons — число неспаренных электронов (радикалов).

MaxPartialCharge, MinPartialCharge, MaxAbsPartialCharge, MinAbsPartialCharge — экстремальные значения частичных зарядов на атомах.

FpDensityMorgan1, FpDensityMorgan2, FpDensityMorgan3 — плотность фингерпринтов Morgan радиуса 1, 2 и 3 на атом.

BCUT2D_MWHI, BCUT2D_MWLOW — BCUT-дескрипторы по массе (высокие и низкие значения), используются в QSAR.
BCUT2D_CHGHI, BCUT2D_CHGLO — BCUT по заряду.
BCUT2D_LOGPHI, BCUT2D_LOGPLOW — BCUT по логарифму распределения октанол-вода (логP).
BCUT2D_MRHI, BCUT2D_MRLOW — BCUT по молярной рефракции.

AvgIpc — среднее информационное содержание (Ipc) молекулы.
BalabanJ — индекс связности Балабана, топологический дескриптор.
BertzCT — топологическая сложность по Берцу.

Chi0, Chi0n, Chi0v, ..., Chi4n, Chi4v — набор индексных дескрипторов Кьереса (Kier & Hall chi indices), основаны на структуре и гибридизации атомов.

HallKierAlpha — коэффициент α Кьера, описывает насыщенность.
Ipc — общее информационное содержание.
Kappa1, Kappa2, Kappa3 — топологические дескрипторы Каппы (формы и гибкости молекулы).
LabuteASA — оценка площади доступной для растворителя.

PEOE_VSA1–PEOE_VSA14 — атомные поверхности, сгруппированные по значениям частичных зарядов (по методу PEOE).
SMR_VSA1–SMR_VSA10 — атомные поверхности по группам логP.
SlogP_VSA1–SlogP_VSA12 — атомные поверхности, сгруппированные по значению логP.
TPSA — суммарная полярная поверхность (topological polar surface area), важна для проницаемости.

EState_VSA1–EState_VSA11 — распределение электронной топологии (EState) по поверхностям.
VSA_EState1–VSA_EState10 — аналогичные дескрипторы, совмещающие EState и VSA.

FractionCSP3 — доля sp³-гибридизированных углеродов, отражает трёхмерность молекулы.
HeavyAtomCount — количество тяжёлых (не водородных) атомов.
NHOHCount — число атомов N и OH-групп.
NOCount — число атомов N и O.
NumAliphaticCarbocycles, NumAliphaticHeterocycles, NumAliphaticRings — количество алифатических карбо- и гетероциклов.
NumAromaticCarbocycles, NumAromaticHeterocycles, NumAromaticRings — количество ароматических карбо- и гетероциклов.
NumHAcceptors, NumHDonors — количество доноров и акцепторов водородных связей.
NumHeteroatoms — количество гетероатомов (не C и H).
NumRotatableBonds — количество вращающихся связей.
NumSaturatedCarbocycles, NumSaturatedHeterocycles, NumSaturatedRings — насыщенные циклические структуры.
RingCount — общее число циклов.
MolLogP — логарифм коэффициента распределения октанол-вода.
MolMR — молярная рефракция.

fr_* — набор бинарных и количественных дескрипторов (fragment counts), обозначающих наличие определённых химических фрагментов:

    fr_Al_COO, fr_Ar_N, fr_benzene, fr_ketone, fr_urea и др.

    Каждый дескриптор показывает количество соответствующих подструктур в молекуле (например, альдегидов, амидов, нитрогрупп, ароматических колец и т.д.).


Проанализируем признаки на предмет полезности для решения поставленных задач классификации и регрессии.

 1. IC50, CC50, SI
Описание: Целевые переменные. IC50 — активность (чем ниже, тем лучше), CC50 — токсичность, SI = CC50 / IC50 — селективность.
Используются как целевые переменные.

2. Электронные индексы (EState, PartialCharge, MaxAbsEStateIndex и др.)
Описание: Отражают электронную структуру молекулы, распределение зарядов.
Полезность:
    IC50: высокая. Электронные свойства влияют на связывание с биомишенями.
    CC50: средняя. Электронная плотность может влиять на неспецифичную токсичность.
    SI: средняя, косвенная.
    Классификации: полезны, особенно для IC50 и SI > 8 (разделение по активности).

3. qed, MolWt, ExactMolWt, HeavyAtomMolWt, NumValenceElectrons
Описание: Общие физико-химические свойства.
Полезность:
    IC50: высокая. Вес и drug-likeness сильно связаны с фармакологической активностью.
    CC50: высокая. Тяжёлые молекулы могут быть более токсичными.
    SI: средняя.
    Классификации: эффективны для всех задач, особенно медианных классификаторов.

4. PartialCharges (Max/Min/Abs)
Описание: Частичные заряды атомов, влияют на взаимодействие с белками.
Полезность:
    IC50: высокая.
    CC50: средняя.
    SI: средняя.
    Классификации: полезны при обучении деревьев или градиентного бустинга.

5. Morgan фингерпринты (FpDensityMorgan1–3)
Описание: Числовые векторы, отражающие локальную структуру атомов.
Полезность:
    IC50: высокая.
    CC50: средняя.
    SI: зависит от контекста, может быть полезен.
    Классификации: особенно полезны для моделей с высокой вариативностью.

6. BCUT-дескрипторы
Описание: Комбинации атомных свойств (заряд, масса, логP) и топологии.
Полезность:
    IC50: высокая.
    CC50: высокая.
    SI: хорошая. Эти признаки хорошо разделяют "плохие" и "хорошие" соединения.
    Классификации: универсально полезны, особенно для SI > 8.

7. Topological descriptors (AvgIpc, BalabanJ, BertzCT, Chi, Kappa, Ipc)**
Описание: Связаны с формой и сложностью молекулы.
Полезность:
    IC50: высокая.
    CC50: средняя.
    SI: полезность зависит от задачи.
    Классификации: сильны при использовании ансамблевых моделей.

8. LabuteASA, TPSA
Описание: Площадь поверхности, доступная для взаимодействия с растворителем.
Полезность:
    IC50: высокая.
    CC50: высокая.
    SI: может быть полезен для исключения липофильных токсичных молекул.
    SI > 8: полезны для фильтрации активных, но нетоксичных соединений.

9. PEOE_VSA, SMR_VSA, SlogP_VSA, EState_VSA, VSA_EState
Описание: Поверхностные дескрипторы по разным шкалам (заряд, полярность, логP и т.д.).
Полезность:
    IC50: высокая.
    CC50: высокая.
    SI: хорошая.
    Классификации: обеспечивают высокую дифференциацию, особенно в задачах с порогом.

10. Фрагменты (fr_*)
Описание: Наличие или количество специфических подструктур (функциональные группы, ароматические кольца, гетероциклы и т.д.).
Полезность:
    IC50: очень высокая, особенно для узнаваемых фармакофоров.
    CC50: высокая, позволяют выделить токсофоры.
    SI: отличная для задач SI > 8.
    Классификации: одни из лучших признаков для дерева решений, логистики и бустинга.

11. Простые дескрипторы (RingCount, NumRotatableBonds, NumHAcceptors/Donors, FractionCSP3 и др.)
Описание: Структурные свойства: гибкость, ароматичность, способность к водородным связям.
Полезность:
    IC50: высокая.
    CC50: высокая.
    SI: хорошая.
    SI > 8: позволяют выделить сбалансированные молекулы.

Резюме по задачам:
    IC50 (регрессия, классификация): полезны почти все признаки, особенно структурные, электронные, фрагментные.
    CC50: приоритет — масса, площадь, водородные связи, заряд.
    SI: комбинация активность/токсичность, лучше работают обобщённые признаки (BCUT, фрагменты, TPSA).
    SI > 8: наиболее чувствительны к drug-likeness, TPSA, qed, функциональным группам, липофильности (логP), связанным с безопасностью.

''')
print('\nДля большей наглядности сведём полученную информацию в таблицу.')
feature_applicability_df = pd.read_csv('../data/feature_applicability.csv')
print(feature_applicability_df)
print(tabulate(feature_applicability_df, headers='keys', tablefmt='fancy_grid'))

print('''\nВывод: все признаки полезны для решения всех задач. 
Будем использовать все, плюс сгенерированные в результате фича инжениринга. 
Потом с помощью РСА понизим размерность в процессе построения модели.''')

print("\nОписательная статистика признаков:")
print(df.describe().T)
print('''\nВыводы:
1. Биологические переменные (IC50, CC50, SI)
1.1. IC50: сильная положительная асимметрия, медиана около 47, максимум > 4000
1.2. CC50: также асимметрично, медиана около 411, максимум > 4500
1.3. SI: экстремально широкий диапазон от 0.01 до 15620, медиана около 3.8
1.4. Вывод: требуется логарифмическое преобразование IC50, CC50 и особенно SI

2. Молекулярные характеристики
2.1. MolWt, ExactMolWt, HeavyAtomMolWt — диапазон от 100 до 900, большинство значений 250–400
2.2. LabuteASA и TPSA — разброс до 350–400, средние значения умеренные
2.3. NumValenceElectrons, HeavyAtomCount, NumRotatableBonds — высокая вариативность
2.4. Вывод: требуется нормализация и масштабирование значений

3. Зарядовые характеристики
3.1. MaxPartialCharge и MinPartialCharge — сбалансированы, присутствует широкий диапазон
3.2. MaxAbsPartialCharge ≈ 0.4–0.5, MinAbsPartialCharge — близки к нулю
3.3. Вывод: возможно использование производных признаков — разностей, отношений, логарифмов

4. Топологические индексы
4.1. Chi, Kappa, BertzCT — распределены умеренно, значительная вариативность
4.2. Ipc — аномально высокое среднее и разброс, максимум 3.95e+13
4.3. Вывод: требуется логарифмическое преобразование Ipc и BertzCT

5. Поверхностные атомные параметры (VSA)
5.1. Многие признаки имеют нулевую медиану и спарсные распределения
5.2. Примеры: PEOE_VSA14, EState_VSA11, SlogP_VSA9 — медиана и 75% равны 0
5.3. Вывод: признаки можно агрегировать (сумма), понизить размерность (PCA) или удалить

6. Фрагментные признаки (fr_*)
6.1. Большинство бинарные, медиана и 75-й перцентиль равны 0
6.2. Исключения: fr_benzene, fr_C_O, fr_ketone — встречаются чаще
6.3. Вывод: использовать агрегацию по группам, фильтрацию по дисперсии

7. Общие рекомендации
7.1. Логарифмировать: IC50, CC50, SI, Ipc, BertzCT, MolWt
7.2. Стандартизировать признаки с широким диапазоном (z-score, PowerTransformer)
7.3. Удалить константные признаки (например, NumRadicalElectrons, fr_* = 0 всегда)
7.4. Снизить размерность признаков: VSA, fr_, Chi, BCUT* — через PCA, SelectKBest
7.5. Добавить производные признаки: разности, отношения, логарифмы (например, TPSA / MolWt)''')

# Анализ пропусков.
print("\nАнализ пропусков.")
missing = df.isnull().sum()
missing = missing[missing > 0].sort_values(ascending=False)
print("\nПризнаки с пропущенными значениями:")
print(missing)
print("\nВывод: пропусков мало, можно просто удалить.")

# Проведём предобработку данных
print("\nПроведём предобработку данных")

# Удалим явно ненужную колонку
print("\nУдалим явно ненужную колонку")
if "Unnamed: 0" in df.columns:
    df.drop(columns=["Unnamed: 0"], inplace=True)

# Есть пропуски, но их очень мало, просто удалим их.
print("\nЕсть пропуски, но их очень мало, просто удалим их.")
target_cols = ['IC50', 'CC50', 'SI']
df = df.dropna()

# Проведём анализ распределения целевых признаков. Визуализируем распределения с помощью гистограмм.
print("\nПроведём анализ распределения целевых признаков. Визуализируем распределения с помощью гистограмм.")

visualise_distributions(df, target_cols)

# Проведём анализ выбросов. Визуализируем с помощью ящиков с усами.
print("\nПроведём анализ выбросов. Визуализируем с помощью ящиков с усами.")

visualise_box_plots(df, target_cols)
# Присутствуют выбросы. Так как из теоретической справки нам известно, что IC50 более 1000 это почти всегда выброс и очень токсично.
# CC50 может быть каким угодно, чем больше тем менее токсично. SI лучше пересчитать, потому как оно вычисляется как CC50 / IC50, и обычно не бывают выше 1000.
# Следовательно, есть выбросы и их нужно убрать. Для начала обрежем по верхнему перцентилю (например, 99-й).
print('''\nПрисутствуют выбросы. Так как из теоретической справки нам известно, что IC50 более 1000 это почти всегда выброс и очень токсично. 
CC50 может быть каким угодно, чем больше тем менее токсично. 
SI лучше пересчитать, потому как оно вычисляется как CC50 / IC50, и обычно не бывают выше 1000. 
Следовательно, есть выбросы и их нужно убрать. Для начала обрежем по верхнему перцентилю (например, 99-й).''')

for col in target_cols:
    upper = df[col].quantile(0.99)
    df = df[df[col] <= upper]

# Удалим строки, в которых значения целевых признаков можно считать выбросами.
print('\nУдалим строки, в которых значения целевых признаков можно считать выбросами.')
df = df[df['IC50'] < 1000]
df = df[df['CC50'] < 3000]
df['SI'] = df['CC50'] / df['IC50']
df = df[df['SI'] < 1000]

# Так как распределения целевых признаков сильно скошены, а это ухудшит обучение моделей, они требуют логарифмирования для приведения к виду более похожему на нормальное распределение.
print('''\nТак как распределения целевых признаков сильно скошены, а это ухудшит обучение моделей, 
они требуют логарифмирования для приведения к виду более похожему на нормальное распределение.''')
# Проведём логарифмирование, добавим новые признаки на основе целевых.
print("\nПроведём логарифмирование, добавим новые признаки на основе целевых.")
for col in target_cols:
    log_col = f"log_{col.split(',')[0]}"
    df[log_col] = np.log1p(df[col])

# Расширим перечень целевых признаков добавив логарифмированные.
print("\nРасширим перечень целевых признаков добавив логарифмированные.")
target_cols = ['IC50', 'CC50', 'SI', 'log_IC50', 'log_CC50', 'log_SI']

# Визуализируем распределения логарифмированных и нет целевых признаков с помощью гистограмм после удаления выбросов.
print('''\nВизуализируем распределения логарифмированных и не логарифмированных целевых признаков 
с помощью гистограмм после удаления выбросов.''')

visualise_distributions(df, target_cols)

# Краткий итог
print("\nКраткий итог")
print(f"Размер после очистки: {df.shape}")
print("Добавленные признаки:", target_cols)

### Визуализируем корреляцию между целевыми признаками, в том числе созданными на их основе.
print("\nВизуализируем корреляцию между целевыми признаками, в том числе созданными на их основе.")
plt.figure()
sns.heatmap(df[target_cols].corr(), annot=True, cmap='coolwarm')
plt.title("Корреляции между IC50, CC50 и SI и логарифмированными версиями")
plt.show()

### Визуализируем корреляцию между всеми признаками, в том числе созданными на их основе.
print('''\nВизуализировать корреляцию между всеми признаками, в том числе созданными на их основе не будем. 
Признаков много, график получается нечитабельный''')

# Корреляция между логарифмированными признаками выше чем между оригинальными. Далее для обучения моделей регрессии следует использовать логарифмированные признаки.
print('''\nКорреляция между логарифмированными признаками выше чем между оригинальными. 
Далее для обучения моделей регрессии следует использовать логарифмированные признаки. 
А само наличие высокой корреляции позитивно скажется на качестве построенных моделей.''')

# Построим корреляционную матрицу всех признаков.
print("\nПостроим корреляционную матрицу всех признаков.")
corr_matrix = df.corr(numeric_only=True)
high_corr = corr_matrix[target_cols].drop(index=target_cols)

# Есть признаки высоко скоррелированные между собой, то-есть мультиколлинеарность и признаки мало коррелированные с таргетами. Решать эту проблему будем используя PCA.
print('''\nЕсть признаки высоко скоррелированные между собой, то-есть мультиколлинеарность и 
признаки мало коррелированные с таргетами. Решать эту проблему будем используя PCA.''')

# Покажем наиболее коррелирующие с таргетами признаки. Эти признаки имеют наибольшую линейную связь с таргетом. Они приоритетны для моделей.
print('''\nПокажем наиболее коррелирующие с таргетами признаки. 
Эти признаки имеют наибольшую линейную связь с таргетом. Они приоритетны для моделей.''')
for target in target_cols:
    visualise_top_correlated_features(corr_matrix, target, target_cols, 10)

# Проверка на дисбаланс классов для задач классификации, важно для выбора метрик (AUC, F1 и пр.)
print("Проверка на дисбаланс классов для задач классификации, важно для выбора метрик (AUC, F1 и пр.)")
df["IC50>median"] = (df["IC50"] > df["IC50"].median()).astype(int)
df["CC50>median"] = (df["CC50"] > df["CC50"].median()).astype(int)
df["SI>median"] = (df["SI"] > df["SI"].median()).astype(int)
df["SI>8"] = (df["SI"] > 8).astype(int)

class_targets = ["IC50>median", "CC50>median", "SI>median", "SI>8"]
print('\nВизуализируем баланс классов для поставленных задач классификации.')
visualise_class_balances(df, class_targets)

print('\nКлассы достаточно сбалансированы для построения классификации.')

print('''\nВыводы:
1. Есть ненужный признак который можно удалить.
2. Распределения целевых переменных сильно скошены и содержат выбросы, поэтому мы их логарифмировали и очистили.
3. Выделили наиболее полезные признаки для построения моделей. В дальнейшем будем использовать PCA.
4. Классы достаточно сбалансированы для построения классификации.
5. Изучая теорию пришли к выводу что можно провести фича инжениринг: 
- Логарифмирование сильно скошенных целевых переменных
- Создание бинарных меток для задач классификации
- Взаимодействия признаков (например, SI = CC50 / IC50 возможно переопределить)
- Статистические производные признаки — например, среднее/сумма/разность между группами дескрипторов
- Группировка похожих дескрипторов — по типу (например, все fr_ или VSA_, и брать суммы или PCA)''')

print("\nEDA завершён. Можно переходить к построению моделей.")
